Вопросы по Machine Learning

Многие ответы взяты из этой [очень крутой статьи](https://vas3k.ru/blog/machine_learning/)
<details>
<summary>Вопрос?</summary>
<div> <br />
	Тело ответаа
	<p></p>
	<b></b>

</div>
</details>


<details>
<summary><b>На что делится Машинное обучение?</b></summary>
<div> <br />
	<img width=650 src="https://github.com/Lisstrange/interviews/blob/master/images/7ry.jpg" alt="bench">
</div>
</details>

<details>
<summary><b>В чем отличие градиентного бустинга над деревьями от случайного леса? Какие базовые параметры настраиваются?</b></summary>
<div> <br />
  
Оба алгоритма являются ансамблями, но реализуют разные подходы: бустинг и беггинг соотвествтенно.  

 **Ансамбль** - набор из моделей, решающих одну задачу, результаты работы которых компонуются так, чтобы повысить эффективность и точность, в сравнении с прогнозом одной модели.  
 
 **Бустинг** - подход, при котором модели обучаются последовательно.  
 Эта техника использует идею о том, что следующая модель будет учится на ошибках предыдущей. Они имеют неравную вероятность появления в последующих моделях, и чаще появятся те, что дают наибольшую ошибку. Обучающая выборка на каждой итерации определяется, исходя из ошибок классификации на предыдущих итерациях. Из-за того, что предсказатели обучаются на ошибках, совершенных предыдущими, требуется меньше времени для того, чтобы добраться до реального ответа. 
	
  Плюсы: быстрый и точный
	
  Минусы: переобучается и не параллелится
	<img width=550 src="https://github.com/Lisstrange/interviews/blob/master/images/boosting.jpg" alt="bench">
	
	
 **Беггинг** - подход, при котором несколько базовых моделей обучаются параллельно на различных подвыборках, и на различных признаках. Результаты обучения всех моделей усредняются.  
 Эффективность бэггинга достигается благодаря тому, что базовые алгоритмы, обученные по различным подвыборкам, получаются достаточно различными, и их ошибки взаимно компенсируются при голосовании, а также за счёт того, что объекты-выбросы могут не попадать в некоторые обучающие подвыборки. Случайный лес - беггинг, в основе которого лежат модели деревьев решений.
	
  Плюсы: довольно точен, устойчив к выбросам
	
  Минусы: очень большой размер моделей, которые получаются в результате
		<img width=550 src="https://github.com/Lisstrange/interviews/blob/master/images/bagging.jpg" alt="bench">
  
  Безовые параметры зависят от типа решаемой задачи (классификация, регрессия) и выбранной базовой модели. Основной общий параметр - число деревьев и их глубина. 
</div>
</details>



<details>
<summary><b>Какой функционал оптимизируется в задаче линейной регрессии? Как записать это в векторной записи?</b></summary>
<div> <br />
	<p></p>
	<b></b>

<img width=400 src="https://github.com/Lisstrange/interviews/blob/master/images/extra.jpg" alt="bench">
<p>Напомню, что <b>линейная регрессия</b> - это метод восстановления зависимости между двумя переменными. Её оптимизация сводится к максимизации прадоподобия, что эквивалентно минимизации среднеквадратичной ошибки (MSE), которая широко используется в реальных задачах.  </p>
<img width=400 src="https://github.com/Lisstrange/interviews/blob/master/images/vector_mse.jpeg" alt="bench">

</div>
</details>




<details>
<summary><b>Виды метрик машинного обучения?</b></summary>
<div> <br />
	<p></p>
	<b></b>
  
<b>Классификация:</b>
  * accuracy
  * precision 
  * recall
  * F-measure
  * AUC-ROC и AUC-PR
  * Logistic Loss (*Данная метрика нечасто выступает в бизнес-требованиях, но часто — в задачах на kaggle. [Крутая статья](https://dyakonov.org/2018/03/12/%d0%bb%d0%be%d0%b3%d0%b8%d1%81%d1%82%d0%b8%d1%87%d0%b5%d1%81%d0%ba%d0%b0%d1%8f-%d1%84%d1%83%d0%bd%d0%ba%d1%86%d0%b8%d1%8f-%d0%be%d1%88%d0%b8%d0%b1%d0%ba%d0%b8/#more-6139)* )  
  
<b>Регрессия</b>
  * MSE
  * R<sup><small>2</small></sup> ([Коэффициент детерминации](https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D1%8D%D1%84%D1%84%D0%B8%D1%86%D0%B8%D0%B5%D0%BD%D1%82_%D0%B4%D0%B5%D1%82%D0%B5%D1%80%D0%BC%D0%B8%D0%BD%D0%B0%D1%86%D0%B8%D0%B8))
  * MAE
  * Квантильная ошибка (*нормальных мануалов не нашел, в двух словах - сильнее штрафует за недопрогноз, чем за перепрогноз*)
  
<b>Кластеризация</b>(*почитать можно [тут](https://habr.com/ru/company/ods/blog/325654/)*)
  * Adjusted Rand Index (ARI)
  * Adjusted Mutual Information (AMI)
  * Homogenity
  * Completeness
  * V-measure
  * Silhouette



<b>Ренжирования</b>(*почитать можно [тут](https://habr.com/ru/company/econtenta/blog/303458/)*)
  * Mean average precision (map@K)
  * Precision at K (Precision@K)
  * Average precision at K (ap@K)
  * Mean average precision at K (map@K)
  * Normalized Discounted Cumulative Gain(NDCG)
  * Normalized Discounted Cumulative Gain (CG@K)
  * Discounted Cumulative Gain at K (DCG@K)
  * Normalized Discounted Cumulative Gain at K (nDCG@K)
  * Mean reciprocal rank (MRR)
  * Метрики на основе ранговой корреляции
  * Метрики на основе каскадной модели поведения
	
	
	
<b>Так же есть неформализованные метрики качества рекомендательных систем, которые нужно учитывать</b>
  * Разнообразие (deversity): например, число рекомендаций из разных категорий или степень различия рекомедаций между сессиями пользователя 
  * Новизна (Novelty): сколько среди рекомендаций объектов новых для пользователя 
  * Покрытие (coverage): доля объектов, которые хотя бы раз побывали в рекомендациях
  * Догадливость (serendipity): способность угадывать неожиданные нетривиальные предпочтения пользователей
</div>
</details>


<details>
<summary><b>Как измерять офлайн/онлайн качество рекомендательных систем?</b></summary>
<div> <br />
	<b>Типичная схема эксперимента:</b>
	 *  разбиваем выборку сессий на обучение и тест;
	 * оптимизируем оффлайн-метрику качества на обучении;
	 * оцениваем качество на тесте и выбираем модель;
	 * внедряем модель в рекомендательный сервис;
	 * проводим AB-тестированием, измеряем онлайн-метрику (деньги или число кликов)
	
	<b>Онлайн и оффлайн-метрики могут быть слабо связаны:</b>
	 * в оффлайне не известно, что пользователь мог бы купить
	 * в оффлайне не известно, что он купил бы без рекомендацицй (порекомендовали то, что он покупает в данный момент)
	<b>Выводы из экспериментов:</b> для улучшений онлайн-точности, нужно оптимизировать разные аспекты качества в оффлайне.
</div>
</details>




<details>
<summary><b>Что такое интерквантили?</b></summary>
<div> <br />
	Интерквартиль (IQR - одна из мер разброса или рассеяния данных. Он равен разности между верхним и нижним (первым и третьим) квартилями. Другими словами IQR -  это ширина интервала, содержащего средние 50% выборки. Таким образом, чем меньше IQR, тем меньше рассеяние. Положительной чертой этого показателя является его устойчивость (робастность), т.е. на него слабо влияют выбросы.

</div>
</details>



<details>
<summary><b>Что такое boxplot?</b></summary>
<div> <br />
	<b>boxplot, ящик с усами, диаграмма размаха</b> — график, использующийся в описательной статистике, компактно изображающий одномерное распределение вероятностей. (*прим. часто помогает визуально определить выбросы*)
	<p></p>
	П.С Выбросы считаются по формуле: (Q1 - 1.5 * IQR or Q3 + 1.5 * IQR). где IQR = Q3−Q1. </p>
	Выглядит следующим образом: 
	<p></p>
<img width=400 src="https://github.com/Lisstrange/interviews/blob/master/images/boxplot.png" alt="bench">
</div>
</details>






<details>
<summary><b>Объяснить, что такое ROC/AUC</b></summary>
<div> <br />
		<p></p>
<img width=400 src="https://github.com/Lisstrange/interviews/blob/master/images/roc_auc.jpg" alt="bench">
		<p></p>
<b>ROC/AUC</b> - это метрика, позволяющая оценить качество бинарной классификации,более информативная, нежели accuracy и показывающая, как часто мы ошибаемся и <b>как</b> мы ошибаемся. Задача бинарной классификации подразумевает два возможных класса, 0 и 1.  

Например, мы хотим понять, будет ли в какой-то день дождь (класс 1) или нет (класс 0). И ошибиться мы можем двумя способами:
    * сказать что дождя не будет, а он пойдет (*False Negative/ложнонегативное предсказание*)
    * сказать что дождь пойдет, а его не будет (*False Positive/ложнопозитивное предсказание*)
Если мы сказали что дождь пошел и угадали - это True Positive/ верноположительное предсказание.

Roc-кривая - это график зависимости True Positive от False Positive, а roc_auc - площадь под этой кривой. (*между синеньким и зелененьким*)  

<img width=400 src="https://github.com/Lisstrange/interviews/blob/master/images/roc_auc2.png" alt="bench">
</div>
</details>




<details>
<summary><b>Что такое F-score и зачем его используют?</b></summary>
<div> <br />
	*Посмотри предыдущий вопрос, про roc_auc, где описано что такое False Negative и False Positive.*

<b>F-score, F-мера</b> - еще одна метрика оценки качества бинарной классификации, так же позволяющая определить как часто мы ошибаемся.

Почему это важно? Мы уже определили, что ошибки бывают двух видов: ложноположительные и ложноотрицательные. И в случае если один из этих типов ошибок нам более страшен - мы постараемся его не допускать, даже в ущерб ошибкам другого типа.

Например тебе нужно определить порок сердца у человека. Тут лучше лишний раз допустить False Positive, и предположить болезнь у здорового человека, нежели упустить больного и не заметить ее. Метрика, которую мы бы максимизировали в этом случае называется <b>recall</b>.

Если мы пытаемся как можно реже делать ложноположительные предсказания - (*например это слишком дорого, как если мы ищем где копать нефть*) - то мы максимизируем метрику <b>precision</b>.  

<b>F-мера</b> же представляет собой гармоническое среднее между <b>precision</b> и <b>recall</b>. Она стремится к нулю, если любой из этих параметров стремится к нулю. Эту метрику мы хотим видеть высокой если нам важен баланс.
</div>
</details>
	

	
	
<details>
<summary><b>Что значит AUC < 0.5? Что с ним делать?</b></summary>
<div> <br />
	В случае бинарной классификации (когда у нас есть только два класса), AUC — эквивалентна вероятности, что классификатор присвоит большее значение классу 1, чем классу 0, а если AUC < 0.5, то можно просто перевернуть выдаваемые значения классификатором потому, что у тебя противоположная ситуация.
</div>
</details>
