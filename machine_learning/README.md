Вопросы по Machine Learning

Многие ответы взяты из этой [очень крутой статьи](https://vas3k.ru/blog/machine_learning/)
<details>
<summary>Вопрос?</summary>
<div> <br />
	Тело ответаа
	<p></p>
	<b></b>

</div>
</details>


<details>
<summary>На что делится Машинное обучение?</summary>
<div> <br />
	<img width=650 src="https://github.com/Lisstrange/interviews/blob/master/images/7ry.jpg" alt="bench">
</div>
</details>

<details>
<summary>В чем отличие градиентного бустинга над деревьями от случайного леса? Какие базовые параметры настраиваются?</summary>
<div> <br />
  
Оба алгоритма являются ансамблями, но реализуют разные подходы: бустинг и беггинг соотвествтенно.  

 **Ансамбль** - набор из моделей, решающих одну задачу, результаты работы которых компонуются так, чтобы повысить эффективность и точность, в сравнении с прогнозом одной модели.  
 
 **Бустинг** - подход, при котором модели обучаются последовательно.  
 Эта техника использует идею о том, что следующая модель будет учится на ошибках предыдущей. Они имеют неравную вероятность появления в последующих моделях, и чаще появятся те, что дают наибольшую ошибку. Обучающая выборка на каждой итерации определяется, исходя из ошибок классификации на предыдущих итерациях. Из-за того, что предсказатели обучаются на ошибках, совершенных предыдущими, требуется меньше времени для того, чтобы добраться до реального ответа. 
	
  Плюсы: быстрый и точный
	
  Минусы: переобучается и не параллелится
	<img width=550 src="https://github.com/Lisstrange/interviews/blob/master/images/boosting.jpg" alt="bench">
	
	
 **Беггинг** - подход, при котором несколько базовых моделей обучаются параллельно на различных подвыборках, и на различных признаках. Результаты обучения всех моделей усредняются.  
 Эффективность бэггинга достигается благодаря тому, что базовые алгоритмы, обученные по различным подвыборкам, получаются достаточно различными, и их ошибки взаимно компенсируются при голосовании, а также за счёт того, что объекты-выбросы могут не попадать в некоторые обучающие подвыборки. Случайный лес - беггинг, в основе которого лежат модели деревьев решений.
	
  Плюсы: довольно точен, устойчив к выбросам
	
  Минусы: очень большой размер моделей, которые получаются в результате
		<img width=550 src="https://github.com/Lisstrange/interviews/blob/master/images/bagging.jpg" alt="bench">
  
  Безовые параметры зависят от типа решаемой задачи (классификация, регрессия) и выбранной базовой модели. Основной общий параметр - число деревьев и их глубина. 
</div>
</details>



<details>
<summary>Какой функционал оптимизируется в задаче линейной регрессии? Как записать это в векторной записи?</summary>
<div> <br />
	<img width=400 src="https://github.com/Lisstrange/interviews/blob/master/images/extra.jpg" alt="bench">
	<p>Напомню, что <b>линейная регрессия</b> - это метод восстановления зависимости между двумя переменными. Её оптимизация сводится к максимизации правдоподобия, что эквивалентно минимизации среднеквадратичной ошибки (MSE), которая широко используется в реальных задачах.  </p>
	<img width=400 src="https://github.com/Lisstrange/interviews/blob/master/images/vector_mse.jpeg" alt="bench">

</div>
</details>

